{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/earneodo/.conda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 13421746937721421366, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11163012301\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 10159787951808281501\n",
       " physical_device_desc: \"device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADBpJREFUeJzt3W+IHPUdx/HPJ2l94J8H2mxD8E+vgojSBxdYQsFYWlpF\nQyHpE2mEcoIQESst9EElFeoDH0jpH/qgBK5NMEabttAG80BaNBTOQhFXSTVWW2252gsxd9GC9lHq\n5dsHN5GL3s6uOzM7m3zfL1h2dn4zO1+W+9zMzuzu1xEhAPmsa7sAAO0g/EBShB9IivADSRF+ICnC\nDyRF+IGkCD+QFOEHkvrEODe2YcOGmJqaGucmgVTm5+d16tQpD7NspfDbvk3STyWtl/SLiHikbPmp\nqSn1er0qmwRQotvtDr3syIf9ttdL+pmk2yXdKGmn7RtHfT4A41XlPf8WSW9ExD8j4rSkX0naXk9Z\nAJpWJfxXSvr3qscLxbxz2N5lu2e7t7S0VGFzAOrU+Nn+iJiNiG5EdDudTtObAzCkKuE/LunqVY+v\nKuYBOA9UCf/zkq6z/VnbF0n6uqTD9ZQFoGkjX+qLiPdtf1PSH7RyqW9fRLxSW2UAGlXpOn9EPCXp\nqZpqATBGfLwXSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+Q\nFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaTG2qIbk+fxxx8vHZ+Zman0/GVdmTdv3lzpuVENe34g\nKcIPJEX4gaQIP5AU4QeSIvxAUoQfSKrSdX7b85Lek7Qs6f2I6NZRFD6eubm5vmOvvfZa6br33ntv\n6fj69etHqumsQ4cO9R3jOn+76viQz5ci4lQNzwNgjDjsB5KqGv6Q9IztF2zvqqMgAONR9bB/a0Qc\nt/1pSU/bfi0iznkDWvxT2CVJ11xzTcXNAahLpT1/RBwv7hclHZK0ZY1lZiOiGxHdTqdTZXMAajRy\n+G1fYvuys9OSbpV0rK7CADSrymH/RkmHbJ99nl9GxO9rqQpA4xwRY9tYt9uNsu93YzRl1+r37t1b\nuu7y8nLpeNXr/GVOnz7d2HNn1e121ev1PMyyXOoDkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU\n4QeSIvxAUoQfSIrwA0kRfiApwg8kRYvuC8CZM2f6jg36ym7ZunU4cOBAo8+P0bHnB5Ii/EBShB9I\nivADSRF+ICnCDyRF+IGkuM5/AVi3rv//8Ko/vV11/bvuuqvv2J133lnpuVENe34gKcIPJEX4gaQI\nP5AU4QeSIvxAUoQfSGrgdX7b+yR9VdJiRHyumHeFpF9LmpI0L+mOiPhPc2XiQvTwww+Xjj/44INj\nqiSnYfb8j0q67UPzHpB0JCKuk3SkeAzgPDIw/BExJ+mdD83eLml/Mb1f0o6a6wLQsFHf82+MiBPF\n9FuSNtZUD4AxqXzCLyJCUvQbt73Lds92b2lpqermANRk1PCftL1Jkor7xX4LRsRsRHQjotvpdEbc\nHIC6jRr+w5JmiukZSU/WUw6AcRkYftsHJf1Z0vW2F2zfLekRSbfYfl3SV4rHAM4jA6/zR8TOPkNf\nrrkWJHP48OHSca7zN4tP+AFJEX4gKcIPJEX4gaQIP5AU4QeS4qe7LwArn7BeW9stusuU1Y3msecH\nkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaS4zn8BsN13rO0W3WVOnTpVOv7ss8+Wjt988811lpMOe34g\nKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrr/GjNm2++WTp+8ODB0nGu81fDnh9IivADSRF+ICnCDyRF\n+IGkCD+QFOEHkhoYftv7bC/aPrZq3kO2j9s+Wty2NVsmgLoNs+d/VNJta8z/SURMF7en6i0LQNMG\nhj8i5iS9M4ZaAIxRlff899t+qXhbcHltFQEYi1HDv0fStZKmJZ2Q9KN+C9reZbtnu7e0tDTi5gDU\nbaTwR8TJiFiOiDOSfi5pS8mysxHRjYhup9MZtU4ANRsp/LY3rXr4NUnH+i0LYDIN/Eqv7YOSvihp\ng+0FSd+X9EXb05JC0rykexqsEUADBoY/InauMXtvA7VgRHv27Ok71uv1StcdNN6kM2fOtLZt8Ak/\nIC3CDyRF+IGkCD+QFOEHkiL8QFL8dPcFYG5uru/Y22+/XbruunXl//+bbNGNdrHnB5Ii/EBShB9I\nivADSRF+ICnCDyRF+IGkuM5/AShrZb2wsDDGSnA+Yc8PJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kR\nfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSQ38Pr/tqyU9JmmjpJA0GxE/tX2FpF9LmpI0L+mO\niPhPc6Win7JW18vLyyOv2zRadLdrmD3/+5K+ExE3Svq8pPts3yjpAUlHIuI6SUeKxwDOEwPDHxEn\nIuLFYvo9Sa9KulLSdkn7i8X2S9rRVJEA6vex3vPbnpK0WdJzkjZGxIli6C2tvC0AcJ4YOvy2L5X0\nW0nfjoh3V49FRGjlfMBa6+2y3bPdW1paqlQsgPoMFX7bn9RK8J+IiN8Vs0/a3lSMb5K0uNa6ETEb\nEd2I6HY6nTpqBlCDgeG3bUl7Jb0aET9eNXRY0kwxPSPpyfrLA9CUYX66+yZJ35D0su2jxbzdkh6R\n9Bvbd0v6l6Q7mikRg5S12a7aYrvJFt2DjgS3bt3a2LYxRPgj4k+S3Gf4y/WWA2Bc+IQfkBThB5Ii\n/EBShB9IivADSRF+ICladKNRu3fv7js2PT1duu6OHXxXrEns+YGkCD+QFOEHkiL8QFKEH0iK8ANJ\nEX4gKa7zJ3fDDTeUjh84cKDS819//fV9xy6++OJKz41q2PMDSRF+ICnCDyRF+IGkCD+QFOEHkiL8\nQFJe6bQ1Ht1uN3q93ti2B2TT7XbV6/X6/dT+OdjzA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSA8Nv\n+2rbf7T9V9uv2P5WMf8h28dtHy1u25ovF0Bdhvkxj/clfSciXrR9maQXbD9djP0kIn7YXHkAmjIw\n/BFxQtKJYvo9269KurLpwgA062O957c9JWmzpOeKWffbfsn2PtuX91lnl+2e7d7S0lKlYgHUZ+jw\n275U0m8lfTsi3pW0R9K1kqa1cmTwo7XWi4jZiOhGRLfT6dRQMoA6DBV+25/USvCfiIjfSVJEnIyI\n5Yg4I+nnkrY0VyaAug1ztt+S9kp6NSJ+vGr+plWLfU3SsfrLA9CUYc723yTpG5Jetn20mLdb0k7b\n05JC0rykexqpEEAjhjnb/ydJa30/+Kn6ywEwLnzCD0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxA\nUoQfSIrwA0kRfiApwg8kRfiBpAg/kNRYW3TbXpL0r1WzNkg6NbYCPp5JrW1S65KobVR11vaZiBjq\n9/LGGv6PbNzuRUS3tQJKTGptk1qXRG2jaqs2DvuBpAg/kFTb4Z9teftlJrW2Sa1LorZRtVJbq+/5\nAbSn7T0/gJa0En7bt9n+m+03bD/QRg392J63/XLRebjXci37bC/aPrZq3hW2n7b9enG/Zpu0lmqb\niM7NJZ2lW33tJq3j9dgP+22vl/R3SbdIWpD0vKSdEfHXsRbSh+15Sd2IaP2asO0vSPqvpMci4nPF\nvB9IeiciHin+cV4eEd+dkNoekvTftjs3Fw1lNq3uLC1ph6S71OJrV1LXHWrhdWtjz79F0hsR8c+I\nOC3pV5K2t1DHxIuIOUnvfGj2dkn7i+n9WvnjGbs+tU2EiDgRES8W0+9JOttZutXXrqSuVrQR/isl\n/XvV4wVNVsvvkPSM7Rds72q7mDVsLNqmS9Jbkja2WcwaBnZuHqcPdZaemNdulI7XdeOE30dtjYhp\nSbdLuq84vJ1IsfKebZIu1wzVuXlc1ugs/YE2X7tRO17XrY3wH5d09arHVxXzJkJEHC/uFyUd0uR1\nHz55tklqcb/Ycj0fmKTOzWt1ltYEvHaT1PG6jfA/L+k625+1fZGkr0s63EIdH2H7kuJEjGxfIulW\nTV734cOSZorpGUlPtljLOSalc3O/ztJq+bWbuI7XETH2m6RtWjnj/w9J32ujhj51XSvpL8XtlbZr\nk3RQK4eB/9PKuZG7JX1K0hFJr0t6RtIVE1TbAUkvS3pJK0Hb1FJtW7VySP+SpKPFbVvbr11JXa28\nbnzCD0iKE35AUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5L6P5r829bnWYRvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63500f4240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = mnist.train.images[:55000,:]\n",
    "x_train.shape\n",
    "randomNum = random.randint(0,55000)\n",
    "image = x_train[randomNum].reshape([28,28])\n",
    "plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(input=x, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "  return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "The discriminator is but a classifier; a binary classifier that decides whether the image comes from the set of sample images or the set of generated images.\n",
    "In this case, a convolutional classifier.\n",
    "https://www.tensorflow.org/tutorials/mnist/pros/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x_image, reuse=False):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        #First Conv and Pool Layers\n",
    "        W_conv1 = tf.get_variable('d_wconv1', [5, 5, 1, 8], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_conv1 = tf.get_variable('d_bconv1', [8], initializer=tf.constant_initializer(0))\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "        h_pool1 = avg_pool_2x2(h_conv1)\n",
    "\n",
    "        #Second Conv and Pool Layers\n",
    "        W_conv2 = tf.get_variable('d_wconv2', [5, 5, 8, 16], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_conv2 = tf.get_variable('d_bconv2', [16], initializer=tf.constant_initializer(0))\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "        h_pool2 = avg_pool_2x2(h_conv2)\n",
    "\n",
    "        #First Fully Connected Layer\n",
    "        W_fc1 = tf.get_variable('d_wfc1', [7 * 7 * 16, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_fc1 = tf.get_variable('d_bfc1', [32], initializer=tf.constant_initializer(0))\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*16])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "        #Second Fully Connected Layer\n",
    "        W_fc2 = tf.get_variable('d_wfc2', [32, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_fc2 = tf.get_variable('d_bfc2', [1], initializer=tf.constant_initializer(0))\n",
    "\n",
    "        #Final Layer\n",
    "        y_conv=(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generator(z, batch_size, z_dim, reuse=False):\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        g_dim = 64 #Number of filters of first layer of generator \n",
    "        c_dim = 1 #Color dimension of output (MNIST is grayscale, so c_dim = 1 for us)\n",
    "        s = 28 #Output size of the image\n",
    "        s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16) #We want to slowly upscale the image, so these values will help\n",
    "                                                                  #make that change gradual.\n",
    "\n",
    "        h0 = tf.reshape(z, [batch_size, s16+1, s16+1, 25])\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        #Dimensions of h0 = batch_size x 2 x 2 x 25\n",
    "\n",
    "        #First DeConv Layer\n",
    "        output1_shape = [batch_size, s8, s8, g_dim*4]\n",
    "        W_conv1 = tf.get_variable('g_wconv1', [5, 5, output1_shape[-1], int(h0.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv1 = tf.get_variable('g_bconv1', [output1_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv1 = tf.nn.conv2d_transpose(h0, W_conv1, output_shape=output1_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv1\n",
    "        H_conv1 = tf.contrib.layers.batch_norm(inputs = H_conv1, center=True, scale=True, is_training=True, scope=\"g_bn1\")\n",
    "        H_conv1 = tf.nn.relu(H_conv1)\n",
    "        #Dimensions of H_conv1 = batch_size x 3 x 3 x 256\n",
    "\n",
    "        #Second DeConv Layer\n",
    "        output2_shape = [batch_size, s4 - 1, s4 - 1, g_dim*2]\n",
    "        W_conv2 = tf.get_variable('g_wconv2', [5, 5, output2_shape[-1], int(H_conv1.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv2 = tf.get_variable('g_bconv2', [output2_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv2 = tf.nn.conv2d_transpose(H_conv1, W_conv2, output_shape=output2_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv2\n",
    "        H_conv2 = tf.contrib.layers.batch_norm(inputs = H_conv2, center=True, scale=True, is_training=True, scope=\"g_bn2\")\n",
    "        H_conv2 = tf.nn.relu(H_conv2)\n",
    "        #Dimensions of H_conv2 = batch_size x 6 x 6 x 128\n",
    "\n",
    "        #Third DeConv Layer\n",
    "        output3_shape = [batch_size, s2 - 2, s2 - 2, g_dim*1]\n",
    "        W_conv3 = tf.get_variable('g_wconv3', [5, 5, output3_shape[-1], int(H_conv2.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv3 = tf.get_variable('g_bconv3', [output3_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv3 = tf.nn.conv2d_transpose(H_conv2, W_conv3, output_shape=output3_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv3\n",
    "        H_conv3 = tf.contrib.layers.batch_norm(inputs = H_conv3, center=True, scale=True, is_training=True, scope=\"g_bn3\")\n",
    "        H_conv3 = tf.nn.relu(H_conv3)\n",
    "        #Dimensions of H_conv3 = batch_size x 12 x 12 x 64\n",
    "\n",
    "        #Fourth DeConv Layer\n",
    "        output4_shape = [batch_size, s, s, c_dim]\n",
    "        W_conv4 = tf.get_variable('g_wconv4', [5, 5, output4_shape[-1], int(H_conv3.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv4 = tf.get_variable('g_bconv4', [output4_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv4 = tf.nn.conv2d_transpose(H_conv3, W_conv4, output_shape=output4_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='VALID') + b_conv4\n",
    "        H_conv4 = tf.nn.tanh(H_conv4)\n",
    "        #Dimensions of H_conv4 = batch_size x 28 x 28 x 1\n",
    "\n",
    "    return H_conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "z_dimensions = 100\n",
    "z_test_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_image = generator(z_test_placeholder, 1, z_dimensions)\n",
    "test_z = np.random.normal(-1, 1, [1,z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "temp = (sess.run(sample_image, feed_dict={z_test_placeholder: test_z}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\notT8Ion6f3+u19wL0TczAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63500a9128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_i = temp.squeeze()\n",
    "plt.imshow(my_i, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "tf.reset_default_graph() #Since we changed our batch size (from 1 to 16), we need to reset our Tensorflow graph\n",
    "\n",
    "sess = tf.Session()\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [None,28,28,1]) #Placeholder for input images to the discriminator\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions]) #Placeholder for input noise vectors to the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx = discriminator(x_placeholder) #Dx will hold discriminator prediction probabilities for the real MNIST images\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions) #Gz holds the generated images\n",
    "Dg = discriminator(Gz, reuse=True)\n",
    "\n",
    "# generator loss is cross entropy agains ones. In logits (-inf, inf, since no softmax at output of disrcim)\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    logits = Dg, \n",
    "    labels = tf.ones_like(Dg))) # ensure forward compatibility: function needs to have logits and labels args explicitly used\n",
    "\n",
    "#discr loss is 1 to real, 0 to fake\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    logits = Dx, \n",
    "    labels = tf.ones_like(Dx)))\n",
    "\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "logits=Dg,\n",
    "labels=tf.ones_like(Dg)))\n",
    "\n",
    "d_loss = d_loss_real + d_loss_fake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### optimizer\n",
    "The discriminator and the generator will be trained sepparately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(tf.get_variable_scope().reuse)\n",
    "adam = tf.train.AdamOptimizer()\n",
    "trainerD = adam.minimize(d_loss, var_list=d_vars)\n",
    "trainerG = adam.minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "iterations = 3000\n",
    "for i in range(iterations):\n",
    "    z_batch = np.random.normal(-1, 1, size=[batch_size, z_dimensions])\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)\n",
    "    real_image_batch = np.reshape(real_image_batch[0],[batch_size,28,28,1])\n",
    "    _,dLoss = sess.run([trainerD, d_loss],feed_dict={z_placeholder:z_batch, \n",
    "                                                     x_placeholder:real_image_batch}) #Update the discriminator\n",
    "    _,gLoss = sess.run([trainerG,g_loss],feed_dict={z_placeholder:z_batch}) #Update the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable generator/g_wconv1 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-7-79f88ee2d2ef>\", line 19, in generator\n    initializer=tf.truncated_normal_initializer(stddev=0.1))\n  File \"<ipython-input-13-cfd24ea77b6b>\", line 2, in <module>\n    Gz = generator(z_placeholder, batch_size, z_dimensions) #Gz holds the generated images\n  File \"/home/earneodo/.conda/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-92b6f8496251>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#z_batch = np.random.normal(-1, 1, size=[1, z_dimensions])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msample_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-79f88ee2d2ef>\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(z, batch_size, z_dim, reuse)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutput1_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_dim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         W_conv1 = tf.get_variable('g_wconv1', [5, 5, output1_shape[-1], int(h0.get_shape()[-1])], \n\u001b[0;32m---> 19\u001b[0;31m                                   initializer=tf.truncated_normal_initializer(stddev=0.1))\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mb_conv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'g_bconv1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput1_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         H_conv1 = tf.nn.conv2d_transpose(h0, W_conv1, output_shape=output1_shape, \n",
      "\u001b[0;32m/home/earneodo/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1201\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1204\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1205\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/home/earneodo/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1090\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/home/earneodo/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/home/earneodo/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/earneodo/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    740\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 742\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    743\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable generator/g_wconv1 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-7-79f88ee2d2ef>\", line 19, in generator\n    initializer=tf.truncated_normal_initializer(stddev=0.1))\n  File \"<ipython-input-13-cfd24ea77b6b>\", line 2, in <module>\n    Gz = generator(z_placeholder, batch_size, z_dimensions) #Gz holds the generated images\n  File \"/home/earneodo/.conda/envs/py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#sample_image = generator(z_placeholder, 1, z_dimensions)\n",
    "z_batch = np.random.normal(-1, 1, size=[batch_size, z_dimensions])\n",
    "#z_batch = np.random.normal(-1, 1, size=[1, z_dimensions])\n",
    "\n",
    "sample_image = generator(z_batch, batch_size, z_dimensions)\n",
    "\n",
    "temp = (sess.run(sample_image, feed_dict={z_placeholder: z_batch}))\n",
    "my_i = temp.squeeze()\n",
    "plt.imshow(my_i, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(?, 100), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/home/earneodo/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1063\u001b[0m             subfeed_t = self.graph.as_graph_element(subfeed, allow_tensor=True,\n\u001b[0;32m-> 1064\u001b[0;31m                                                     allow_operation=False)\n\u001b[0m\u001b[1;32m   1065\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/earneodo/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3034\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3035\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/earneodo/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3113\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3115\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder:0\", shape=(?, 100), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-df7a4a296c5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#sample_image = generator(z_test_placeholder, 1, z_dimensions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_dimensions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz_test_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_z\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmy_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray_r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/earneodo/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/earneodo/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1065\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: '\n\u001b[0;32m-> 1067\u001b[0;31m                             + e.args[0])\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(?, 100), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "z_dimensions = 100\n",
    "#z_test_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])\n",
    "#sample_image = generator(z_test_placeholder, 1, z_dimensions)\n",
    "test_z = np.random.normal(-1, 1, [1,z_dimensions])\n",
    "temp = (sess.run(sample_image, feed_dict={z_test_placeholder: test_z}))\n",
    "my_i = temp.squeeze()\n",
    "plt.imshow(my_i, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
